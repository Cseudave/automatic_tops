{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0oaV69iaTiC_",
        "bzOMqbshUkck",
        "NG_eYW29Z-Ko",
        "IkeNSNbahS1Q",
        "1RqyiLRPluFm",
        "r0jnE0zqrGwM",
        "lYo71E3WrMiL",
        "2wv-m8-3tUta",
        "-1MZqIzqwc5E",
        "K_YwM-ojxGeC",
        "j2pFu83nyDSG"
      ],
      "authorship_tag": "ABX9TyP0bi9tBx+DMqNGcC+OTO2H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cseudave/automatic_tops/blob/main/Web_Scraping_Anilist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Web Scraping"
      ],
      "metadata": {
        "id": "0oaV69iaTiC_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Anilist"
      ],
      "metadata": {
        "id": "NG_eYW29Z-Ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternativamente se usará los datos de otra página, o bien, comparando el rendimiento de ambos casos y poder elegir la mejor opción"
      ],
      "metadata": {
        "id": "t-qHQwDZamoC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido a cambios en el sistema operativo de las computadoras de google colab es necesario correr el siguiente script para poder utilizar Selenium"
      ],
      "metadata": {
        "id": "acrecDmXa2b0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n",
        "\n",
        "# Install chromium and chromium-driver\n",
        "apt-get update\n",
        "apt-get install chromium chromium-driver\n",
        "\n",
        "# Install selenium\n",
        "pip install selenium"
      ],
      "metadata": {
        "id": "PqEvF2jdZ_W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos librerías \n",
        "import re\n",
        "import numpy as np\n",
        "from numpy import arange\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import csv\n",
        "import time\n",
        "import random"
      ],
      "metadata": {
        "id": "T5vkwwk9bKpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_anilist(url):\n",
        "  # Se configura el driver para usar selenium\n",
        "  options = Options()\n",
        "  options.add_argument(\"--headless\")\n",
        "  options.add_argument(\"--no-sandbox\")\n",
        "  options.headless = True\n",
        "  driver = webdriver.Chrome(\"/usr/bin/chromedriver\", options=options)\n",
        "  driver.get(url)\n",
        "  driver.maximize_window()\n",
        "\n",
        "  time.sleep(random.uniform(3, 4))\n",
        "\n",
        "  # Se copia el contenido de la url como si se hiciera con un mouse\n",
        "  data = driver.find_element(By.XPATH, \"/html/body\").text\n",
        "  driver.close()\n",
        "\n",
        "\n",
        "  return data "
      ],
      "metadata": {
        "id": "OUZjwv_Hb9pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Debido a que todas las páginas comparten una estructura similar, se puede utilizar algunas palabras como referencia para obtener los datos deseados"
      ],
      "metadata": {
        "id": "hL-lM64KcSXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontramos las marcas claves\n",
        "marks = ['Add to List',\n",
        " 'Social',\n",
        "'Format',\n",
        "'Episodes',\n",
        "'Episode Duration',\n",
        "'Status',\n",
        "#'Start Date',\n",
        "#'End Date',\n",
        "'Season',\n",
        "'Average Score',\n",
        "'Mean Score',\n",
        "'Popularity',\n",
        "'Favorites',\n",
        "'Studios',\n",
        "'Producers',\n",
        "'Source',\n",
        "'Hashtag',\n",
        "'Genres',\n",
        "'Romaji',\n",
        "'English',\n",
        "'Native',\n",
        "'Synonyms',\n",
        "'Tags',\n",
        "'External & Streaming links',\n",
        "'Relations',\n",
        "'Characters',\n",
        "'Staff',\n",
        "'Status Distribution',\n",
        "'Score Distribution',\n",
        "'Trailer',\n",
        "'Recommendations',\n",
        "'ThreadsCreate New Thread'\n",
        " ]"
      ],
      "metadata": {
        "id": "xKvvdHKQb1_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtenemos el texto copiado y según las marcas clasificamos los campos con los datos deseados\n",
        "def to_dict(prueba, marks):\n",
        "  nmarks = []\n",
        "  prueba = prueba.split('\\n')\n",
        "  try:\n",
        "    if prueba.index('Overview')  & prueba.index('Stats') < 50:\n",
        "      del prueba[prueba.index('Overview'):prueba.index('Stats') + 1] \n",
        "  except:\n",
        "    None\n",
        "  for mark in marks:\n",
        "    if mark in prueba:\n",
        "      nmarks.append(mark)\n",
        "  cuts = [prueba.index(x) for x in nmarks]\n",
        "  valores = [prueba[cuts[i]+1:cuts[i+1]] for i in range(0, len(cuts) - 1)]\n",
        "  ndict = {}\n",
        "  for x, y in zip(nmarks, valores):\n",
        "    ndict[x] = y\n",
        "  return ndict"
      ],
      "metadata": {
        "id": "6cm5rJH3cjNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función anterior solo requiere la lista de urls seleccionados. Por lo que se crea a mano una hoja de calculo con ellos, llamado anilinks.xlsx"
      ],
      "metadata": {
        "id": "hHrY4QzRdudg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('anilinks.xlsx', sheet_name='Hoja 1' )"
      ],
      "metadata": {
        "id": "qioONaqIeDnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def more_anilist(links, db, marks):\n",
        "  for i in range(len(db), len(links)):\n",
        "    data = get_anilist(links[i])\n",
        "    db.append(to_dict(data, marks))\n",
        "    print(i, links[i])\n",
        "  return db"
      ],
      "metadata": {
        "id": "dXm3kdKBe0BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una lista vacia para agregar los diccionarios con los datos de cada link\n",
        "db = []\n",
        "db = more_anilist(links, db, marks)"
      ],
      "metadata": {
        "id": "3TMIzUn-fBzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En caso de buscar solo un par de links, por ejemplo\n",
        "# links = [\n",
        "# 'https://anilist.co/anime/113717/Ousama-Ranking']"
      ],
      "metadata": {
        "id": "5S8H1dCcekij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# En caso de agregar manualmente un registro:\n",
        "# Ejemplo reducido de cómo luce el texto copiado\n",
        "\n",
        "data = '''\n",
        "\n",
        "Add to List\n",
        "Akiba Meido sensou \n",
        "Akihabara is the center of the universe for the coolest hobbies and quirkiest amusements. In the spring of 1999, bright-eyed Nagomi Wahira moves there with dreams of joining a maid café. She quickly dons an apron at café Ton Tokoton, AKA the Pig Hut. But adjusting to life in bustling Akihabara isn’t as easy as serving tea and delighting customers. Paired with the dour Ranko who never seems to smile, Nagomi must do her best to elevate the Pig Hut over all other maid cafés vying for top ranking. Along the way she’ll slice out a place for herself amid the frills and thrills of life at the Pig Hut. Just when Nagomi’s dreams are within her grasp, she discovers not everything is as it seems amid the maid cafés of Akihabara.\n",
        "\n",
        " #45 Highest Rated 2022\n",
        " #62 Most Popular 2022\n",
        "Format\n",
        "TV\n",
        "Episodes\n",
        "12\n",
        "Episode Duration\n",
        "24 mins\n",
        "Status\n",
        "Finished\n",
        "Start Date\n",
        "Oct 7, 2022\n",
        "...\n",
        "Recommendations\n",
        "View All Recommendations\n",
        "'''\n",
        "\n",
        "#Traducimos el texto a un diccionario\n",
        "db = [to_dict(data, marks)]\n",
        "#Para poder agregarlo a los registros\n",
        "db = more_anilist(links, db, marks)\n"
      ],
      "metadata": {
        "id": "wGo0JI3efnPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tomamos la base de datos y agregamos el nuevo anime\n",
        "db_new = pd.DataFrame(db)\n",
        "names = []\n",
        "for text in db_new['Add to List']:\n",
        "  names.append(text[0])\n",
        "db_new.insert(0, 'name', names)\n",
        "db_old = pd.read_csv('anilist22_raw.csv')"
      ],
      "metadata": {
        "id": "gqq0bdhmgyKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_full = pd.concat([db_old, db_new], axis=0)\n",
        "db_full.to_csv('anilist22_raw.csv', index=False)"
      ],
      "metadata": {
        "id": "TySChqbbhNj-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}